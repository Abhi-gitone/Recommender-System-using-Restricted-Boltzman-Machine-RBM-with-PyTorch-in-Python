{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a16e9c59",
   "metadata": {},
   "source": [
    "**Dataset**: [MovieLens Dataset](http://grouplens.org/datasets/movielens/) from grouplens.org.\n",
    "\n",
    "**Task**: To build a recommender system using [Restricted Boltzman Machines (RBMs)](http://cms.dm.uba.ar/academico/materias/1ercuat2018/probabilidades_y_estadistica_C/5a89b5075af5cbef5becaf419457cdd77cc9.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "367ee01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## package imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8527c9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## data import\n",
    "\n",
    "train = pd.read_csv('ml-100k/u1.base', sep='\\t', header=None)\n",
    "test = pd.read_csv('ml-100k/u1.test', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "173f6b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>874965758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>876893171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>878542960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>876893119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>889751712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2          3\n",
       "0  1  1  5  874965758\n",
       "1  1  2  3  876893171\n",
       "2  1  3  4  878542960\n",
       "3  1  4  3  876893119\n",
       "4  1  5  3  889751712"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "619ede66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>887431973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>875693118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>878542960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>874965706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>875073198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1  2          3\n",
       "0  1   6  5  887431973\n",
       "1  1  10  3  875693118\n",
       "2  1  12  5  878542960\n",
       "3  1  14  5  874965706\n",
       "4  1  17  3  875073198"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6142e2",
   "metadata": {},
   "source": [
    "**Important**: Columns '0', '1', '2', and '3', represent users, movies, ratings, and timestamps respectively."
   ]
  },
  {
   "cell_type": "raw",
   "id": "2b3400fe",
   "metadata": {},
   "source": [
    "Step 1: Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "474da2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting train and test sets into arrays\n",
    "\n",
    "train = np.array(train, dtype=int)\n",
    "test = np.array(test, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f039abae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting number of users and movies\n",
    "\n",
    "num_users = int(max(max(train[:,0]), max(test[:,0])))\n",
    "num_movies = int(max(max(train[:,1]), max(test[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5323457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5de62ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1682"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "593440ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## coverting datasets into a list of lists of dimension (num_users, num_movies) for pytorch tensor compatibility\n",
    "\n",
    "def convert(data): ## function to convert\n",
    "    \n",
    "    final_list = list() ## initialization\n",
    "    \n",
    "    for user_id in range(1, num_users + 1):\n",
    "        \n",
    "        user_movies = data[:,1][data[:,0]==user_id] ## all movies rated by user\n",
    "        user_ratings = data[:,2][data[:,0]==user_id] ## all ratings by user\n",
    "        \n",
    "        user_all_movies = np.zeros(num_movies) ## user ratings for each movie. 0 for urated morvies.\n",
    "        user_all_movies[user_movies-1] = user_ratings\n",
    "            \n",
    "        final_list.append(user_all_movies)\n",
    "    \n",
    "    return final_list\n",
    "\n",
    "train, test = convert(train), convert(test) ## data format conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc57c440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 3., 4., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d773531e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a266b94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhin\\anaconda3\\envs\\nlp_course\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:233.)\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "## converting into pytorch tensors of dimensions (num_users, num_movies)\n",
    "\n",
    "train = torch.FloatTensor(train)\n",
    "test = torch.FloatTensor(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ab3e397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
       "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 5., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93c282df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e76e4914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([943, 1682])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e0d5f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([943, 1682])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fcf71a4",
   "metadata": {},
   "outputs": [],
   "source": [
    " ## converting into binary ratings\n",
    "\n",
    "## train set\n",
    "\n",
    "train[train == 0] = -1 ## -1 for unrated\n",
    "train[train == 1] = 0\n",
    "train[train == 2] = 0\n",
    "train[train >= 3] = 1\n",
    "\n",
    "## test set\n",
    "\n",
    "test[test == 0] = -1 ## -1 for unrated\n",
    "test[test == 1] = 0\n",
    "test[test == 2] = 0\n",
    "test[test >= 3] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a908976c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  1.,  1.,  ..., -1., -1., -1.],\n",
       "        [ 1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        ...,\n",
       "        [ 1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1.,  1., -1.,  ..., -1., -1., -1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1ff0f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        ...,\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f0e1706",
   "metadata": {},
   "source": [
    "Step 2: Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fef37ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating model architecture\n",
    "\n",
    "class RBM():\n",
    "    \n",
    "    def __init__(self, nh, nv): ## nh-->no. of hidden nodes, nv-->no. of visible nodes \n",
    "        \n",
    "        self.W = torch.randn((nh, nv)) ## W--> weights, parameteres for prob. of visible nodes given hidden nodes\n",
    "        \n",
    "        self.Bhv = torch.randn((1, nh)) ##Bhv--> bias for prob. of hidden nodes given visible node\n",
    "        \n",
    "        self.Bvh = torch.randn(1, nv) ##Bvh--> bias for prob. of visible nodes given hidden node\n",
    "        \n",
    "        ## initialized all weights and biases into tensors of reqd. dimensions based on normal dist. of mean=0 and variance=1\n",
    "        \n",
    "    ## sampling of hidden nodes given visible nodes\n",
    "    \n",
    "    def sample_h(self, x): ## x-->visible neurons\n",
    "        \n",
    "        wx = torch.mm(x, self.W.t()) ## matrix multiplication of visible nodes with transpose of weights\n",
    "        \n",
    "        activate = wx + self.Bhv.expand_as(wx) ## wx + bias(hidden given visible), .expand_as ensure bias is added to all values\n",
    "        \n",
    "        Phv = torch.sigmoid(activate) ## prob. that hidden node fires up for specified visible node for each node\n",
    "        \n",
    "        hv = torch.bernoulli(Phv) ## Phv-->binary, 1 for activate hidden neuron and 0 for don't activate hidden neuron\n",
    "        \n",
    "        return Phv, hv\n",
    "    \n",
    "    ## sampling for visible nodes given visible nodes\n",
    "    \n",
    "    def sample_v(self, y): ## y-->hidden neurons\n",
    "        \n",
    "        wy = torch.mm(y, self.W) ## matrix multiplication of hidden nodes with weights\n",
    "        \n",
    "        activate = wy + self.Bvh.expand_as(wy) ## wx + bias(hidden given visible), .expand_as ensure bias is added to all values\n",
    "        \n",
    "        Pvh = torch.sigmoid(activate) ## prob. that hidden node fires up for specified visible node for each node\n",
    "        \n",
    "        vh = torch.bernoulli(Pvh) ## Phv-->binary, 1 for activate hidden neuron and 0 for don't activate hidden neuron\n",
    "        \n",
    "        return Pvh, vh\n",
    "    \n",
    "    ## function to train model with Contrastive Divergence 1 (Gibbs Sampling)\n",
    "    \n",
    "    ## v0-->visible nodes initially, vk --> visible nodes after k steps, ph0, phk--> prob. of hidden nodes with v0 and vk resp.\n",
    "    \n",
    "    def train(self, v0, vk, ph0, phk): \n",
    "        \n",
    "        self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t() ## weight update\n",
    "        \n",
    "        ## bias update\n",
    "        \n",
    "        self.Bvh += torch.sum((v0 - vk), 0)\n",
    "        \n",
    "        self.Bhv += torch.sum((ph0 - phk), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dce6b8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.RBM"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## instantiating the RBM class\n",
    "\n",
    "nv = len(train[0])\n",
    "nh = 150 ## detect 50 features for a start\n",
    "batch_size = 20 ## for faster training\n",
    "\n",
    "rbm = RBM(nh=nh, nv=nv)\n",
    "\n",
    "type(rbm)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ca7d576a",
   "metadata": {},
   "source": [
    "Step 3: Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eddbb5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1.0     train_loss: 0.16156382858753204\n",
      "epoch: 2.0     train_loss: 0.16344794631004333\n",
      "epoch: 3.0     train_loss: 0.1431935876607895\n",
      "epoch: 4.0     train_loss: 0.16015073657035828\n",
      "epoch: 5.0     train_loss: 0.16109278798103333\n",
      "epoch: 6.0     train_loss: 0.15308526158332825\n",
      "epoch: 7.0     train_loss: 0.1756947785615921\n",
      "epoch: 8.0     train_loss: 0.1648610383272171\n",
      "epoch: 9.0     train_loss: 0.16580310463905334\n",
      "epoch: 10.0    train_loss: 0.17004239559173584\n",
      "epoch: 11.0    train_loss: 0.16344794631004333\n",
      "epoch: 12.0    train_loss: 0.16203485429286957\n",
      "epoch: 13.0    train_loss: 0.16344794631004333\n",
      "epoch: 14.0    train_loss: 0.15873762965202332\n",
      "epoch: 15.0    train_loss: 0.16344794631004333\n",
      "epoch: 16.0    train_loss: 0.17522373795509338\n",
      "epoch: 17.0    train_loss: 0.1714554876089096\n",
      "epoch: 18.0    train_loss: 0.17239755392074585\n",
      "epoch: 19.0    train_loss: 0.15920867025852203\n",
      "epoch: 20.0    train_loss: 0.1540273129940033\n",
      "epoch: 21.0    train_loss: 0.17286857962608337\n",
      "epoch: 22.0    train_loss: 0.16627414524555206\n",
      "epoch: 23.0    train_loss: 0.16203485429286957\n",
      "epoch: 24.0    train_loss: 0.15920867025852203\n",
      "epoch: 25.0    train_loss: 0.16015073657035828\n",
      "epoch: 26.0    train_loss: 0.16344794631004333\n",
      "epoch: 27.0    train_loss: 0.1691003292798996\n",
      "epoch: 28.0    train_loss: 0.15544041991233826\n",
      "epoch: 29.0    train_loss: 0.15496937930583954\n",
      "epoch: 30.0    train_loss: 0.16580310463905334\n",
      "epoch: 31.0    train_loss: 0.17004239559173584\n",
      "epoch: 32.0    train_loss: 0.15920867025852203\n",
      "epoch: 33.0    train_loss: 0.15920867025852203\n",
      "epoch: 34.0    train_loss: 0.16344794631004333\n",
      "epoch: 35.0    train_loss: 0.16439001262187958\n",
      "epoch: 36.0    train_loss: 0.16109278798103333\n",
      "epoch: 37.0    train_loss: 0.16156382858753204\n",
      "epoch: 38.0    train_loss: 0.1648610383272171\n",
      "epoch: 39.0    train_loss: 0.16203485429286957\n",
      "epoch: 40.0    train_loss: 0.16627414524555206\n",
      "epoch: 41.0    train_loss: 0.1648610383272171\n",
      "epoch: 42.0    train_loss: 0.15920867025852203\n",
      "epoch: 43.0    train_loss: 0.1648610383272171\n",
      "epoch: 44.0    train_loss: 0.1629769206047058\n",
      "epoch: 45.0    train_loss: 0.17804992198944092\n",
      "epoch: 46.0    train_loss: 0.15732453763484955\n",
      "epoch: 47.0    train_loss: 0.16391898691654205\n",
      "epoch: 48.0    train_loss: 0.1563824713230133\n",
      "epoch: 49.0    train_loss: 0.15544041991233826\n",
      "epoch: 50.0    train_loss: 0.17239755392074585\n",
      "epoch: 51.0    train_loss: 0.1667451709508896\n",
      "epoch: 52.0    train_loss: 0.17475271224975586\n",
      "epoch: 53.0    train_loss: 0.16862930357456207\n",
      "epoch: 54.0    train_loss: 0.16439001262187958\n",
      "epoch: 55.0    train_loss: 0.16203485429286957\n",
      "epoch: 56.0    train_loss: 0.17098446190357208\n",
      "epoch: 57.0    train_loss: 0.1667451709508896\n",
      "epoch: 58.0    train_loss: 0.1667451709508896\n",
      "epoch: 59.0    train_loss: 0.16957135498523712\n",
      "epoch: 60.0    train_loss: 0.1629769206047058\n",
      "epoch: 61.0    train_loss: 0.17381064593791962\n",
      "epoch: 62.0    train_loss: 0.15779557824134827\n",
      "epoch: 63.0    train_loss: 0.1606217622756958\n",
      "epoch: 64.0    train_loss: 0.1582666039466858\n",
      "epoch: 65.0    train_loss: 0.17381064593791962\n",
      "epoch: 66.0    train_loss: 0.16862930357456207\n",
      "epoch: 67.0    train_loss: 0.16391898691654205\n",
      "epoch: 68.0    train_loss: 0.16344794631004333\n",
      "epoch: 69.0    train_loss: 0.17710787057876587\n",
      "epoch: 70.0    train_loss: 0.1629769206047058\n",
      "epoch: 71.0    train_loss: 0.16439001262187958\n",
      "epoch: 72.0    train_loss: 0.17710787057876587\n",
      "epoch: 73.0    train_loss: 0.15732453763484955\n",
      "epoch: 74.0    train_loss: 0.16815826296806335\n",
      "epoch: 75.0    train_loss: 0.17286857962608337\n",
      "epoch: 76.0    train_loss: 0.16627414524555206\n",
      "epoch: 77.0    train_loss: 0.1691003292798996\n",
      "epoch: 78.0    train_loss: 0.1714554876089096\n",
      "epoch: 79.0    train_loss: 0.1667451709508896\n",
      "epoch: 80.0    train_loss: 0.16156382858753204\n",
      "epoch: 81.0    train_loss: 0.16768723726272583\n",
      "epoch: 82.0    train_loss: 0.1714554876089096\n",
      "epoch: 83.0    train_loss: 0.1606217622756958\n",
      "epoch: 84.0    train_loss: 0.17004239559173584\n",
      "epoch: 85.0    train_loss: 0.1691003292798996\n",
      "epoch: 86.0    train_loss: 0.15732453763484955\n",
      "epoch: 87.0    train_loss: 0.16391898691654205\n",
      "epoch: 88.0    train_loss: 0.15873762965202332\n",
      "epoch: 89.0    train_loss: 0.1733396202325821\n",
      "epoch: 90.0    train_loss: 0.17192651331424713\n",
      "epoch: 91.0    train_loss: 0.1667451709508896\n",
      "epoch: 92.0    train_loss: 0.17710787057876587\n",
      "epoch: 93.0    train_loss: 0.16109278798103333\n",
      "epoch: 94.0    train_loss: 0.17004239559173584\n",
      "epoch: 95.0    train_loss: 0.16391898691654205\n",
      "epoch: 96.0    train_loss: 0.1606217622756958\n",
      "epoch: 97.0    train_loss: 0.1648610383272171\n",
      "epoch: 98.0    train_loss: 0.1540273129940033\n",
      "epoch: 99.0    train_loss: 0.16580310463905334\n",
      "epoch: 100.0   train_loss: 0.17286857962608337\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "counter = 0.\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    for user_id in range(0, num_users-batch_size, batch_size):\n",
    "        \n",
    "        train_loss = 0\n",
    "        \n",
    "        vk = train[user_id: user_id+100] ## changes\n",
    "        \n",
    "        v0 = train[user_id: user_id+100] ## never changes\n",
    "        \n",
    "        ph0,_ = rbm.sample_h(x=v0) ## prob. of hidden nodes being activated given visible nodes at 0\n",
    "        \n",
    "        ## k-steps constrastive divergence\n",
    "        \n",
    "        for k in range(10):\n",
    "            \n",
    "            _,hk = rbm.sample_h(x=vk)\n",
    "            \n",
    "            _,vk = rbm.sample_v(y=hk)\n",
    "            \n",
    "            vk[v0<0] = v0[v0<0] ## maintain all -1 ratings\n",
    "            \n",
    "        phk,_ = rbm.sample_h(x=vk) ## prob. of hidden nodes being activated given visible nodes at k\n",
    "        \n",
    "        rbm.train(v0=v0, vk=vk, ph0=ph0, phk=phk)\n",
    "        \n",
    "        train_loss += torch.mean(torch.abs(v0[v0 >= 0] - vk[v0 >= 0]))\n",
    "        \n",
    "    counter += 1.\n",
    "        \n",
    "    print(f\"epoch: {counter:<{7}} train_loss: {train_loss}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "60f70353",
   "metadata": {},
   "source": [
    "Step 4: Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db4f6d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.21222034768730985\n"
     ]
    }
   ],
   "source": [
    "test_loss_list = list() ## list to collect loss\n",
    "\n",
    "counter = 0.\n",
    "\n",
    "for user_id in range(num_users):\n",
    "        \n",
    "        test_loss = 0\n",
    "        \n",
    "        v = train[user_id: user_id+1] ## VERY IMPORTANT --> use the weights to convert train data into value\n",
    "        \n",
    "        vt = test[user_id: user_id+1] ## real ratings for comparison\n",
    "        \n",
    "        ## k-steps constrastive divergence\n",
    "        \n",
    "        ## blind walk after training with random walk\n",
    "        \n",
    "        if len(vt[vt>=0]) > 0:\n",
    "            \n",
    "            _,h = rbm.sample_h(x=v)\n",
    "            \n",
    "            _,v = rbm.sample_v(y=h)\n",
    "        \n",
    "        test_loss = torch.mean(torch.abs(vt[vt >= 0] - v[vt >= 0]))\n",
    "        \n",
    "        \n",
    "        test_loss_list.append(float(test_loss))\n",
    "        \n",
    "        counter += 1.\n",
    "\n",
    "test_loss_list = [i for i in test_loss_list if i>= 0] ## dealing with NaN losses\n",
    "\n",
    "print(f\"test_loss: {np.mean(test_loss_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255f8b27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
